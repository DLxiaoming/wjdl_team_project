#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çº¯FDPå®æ—¶ç›‘æµ‹è„šæœ¬ï¼ˆç›¸æœºåæ ‡ç³»ç‰ˆæœ¬ï¼‰
- ä½¿ç”¨æœºå™¨äººæ‘„åƒå¤´è¿›è¡Œå®æ—¶FDPæ£€æµ‹
- æ˜¾ç¤ºç»¿è‰²3Dæ¡†å’Œä¸‰ä¸ªåæ ‡è½´ï¼ˆRGBï¼‰
- è¾“å‡ºç›¸æœºåæ ‡ç³»ä¸‹çš„6Dä½å§¿ä¿¡æ¯
- ä¸è¿›è¡ŒåŸºåº§åæ ‡è½¬æ¢
- æ— æŠ“å–åŠŸèƒ½
"""

import os
import sys
import logging
import time
import json
import numpy as np
import cv2
from ultralytics import YOLO
from scipy.spatial.transform import Rotation
import trimesh
import nvdiffrast.torch as dr

from estimater import *
from Utils import *
from last import MMK2RealRobot

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='[%(levelname)s] %(message)s'
    )

def main():
    import argparse
    
    setup_logging()
    
    parser = argparse.ArgumentParser(description='FDPå®æ—¶ç›‘æµ‹ï¼ˆçº¯æ£€æµ‹ï¼Œæ— æŠ“å–ï¼Œä»…ç›¸æœºåæ ‡ï¼‰')
    code_dir = os.path.dirname(os.path.realpath(__file__))
    
    parser.add_argument('--robot_ip', type=str, required=False, default='192.168.11.200')
    
    # æ¨¡å‹å’Œæ•°æ®
    parser.add_argument('--mesh_file', type=str,
                       default=f'{code_dir}/demo_data/tube/mesh/1.obj') #  textured_simple
    parser.add_argument('--yolo_model', type=str,
                       default=f'{code_dir}/best.pt')
    
    # FDPå‚æ•°
    parser.add_argument('--est_refine_iter', type=int, default=10,
                       help='FDPæ³¨å†Œè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--head_pitch', type=float, default=-0.5236,
                       help='å¤´éƒ¨ä¿¯ä»°è§’åº¦ï¼ˆå¼§åº¦ï¼‰ï¼Œé»˜è®¤-30åº¦')
    
    args = parser.parse_args()
    
    print("="*70)
    print("ğŸ” FDPå®æ—¶ç›‘æµ‹ç³»ç»Ÿï¼ˆä»…ç›¸æœºåæ ‡ç³»ï¼‰")
    print("="*70)
    print(f"æœºå™¨äººIP: {args.robot_ip}")
    print(f"å¤´éƒ¨ä¿¯ä»°è§’: {np.degrees(args.head_pitch):.1f}Â° ({args.head_pitch:.4f} rad)")
    print("="*70 + "\n")
    
    logging.info("åˆå§‹åŒ–æœºå™¨äºº...")
    robot = MMK2RealRobot(ip=args.robot_ip)
    time.sleep(2.0)
    
    # è®¾ç½®å¤´éƒ¨è§’åº¦
    logging.info(f"è®¾ç½®å¤´éƒ¨è§’åº¦: {np.degrees(args.head_pitch):.1f}Â°")
    robot.set_robot_head_pose(0.0, args.head_pitch)
    time.sleep(1.0)
    
    # åŠ è½½æ¨¡å‹
    logging.info("åŠ è½½YOLOæ¨¡å‹...")
    yolo_model = YOLO(args.yolo_model)
    
    logging.info("åŠ è½½FoundationPose...")
    mesh = trimesh.load(args.mesh_file)
    to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
    bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)
    
    debug_dir = f'{code_dir}/debug'
    os.makedirs(debug_dir, exist_ok=True)
    
    scorer = ScorePredictor()
    refiner = PoseRefinePredictor()
    glctx = dr.RasterizeCudaContext()
    est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
                        mesh=mesh, scorer=scorer, refiner=refiner, 
                        glctx=glctx, debug_dir=debug_dir, debug=1)
    
    logging.info("âœ“ åˆå§‹åŒ–å®Œæˆ")
    logging.info("="*70)
    
    # ç›¸æœºå†…å‚
    K = np.array([[601.87, 0, 321.05], [0, 601.87, 252.46], [0, 0, 1]])
    camera = robot.camera
    time.sleep(2.0)
    
    print("\n" + "="*70)
    print("ğŸ” å¼€å§‹FDPæ£€æµ‹ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰")
    print("="*70)
    print("æç¤º: æŒ‰ 'r' é‡æ–°æ£€æµ‹, æŒ‰ 'q' é€€å‡ºç¨‹åº\n")
    
    def detect_once():
        """æ‰§è¡Œä¸€æ¬¡FDPæ£€æµ‹"""
        pose_detected = False
        pose_in_camera = None
        vis = None
        
        logging.info("æ­£åœ¨è·å–å›¾åƒ...")
        for img_head, img_depth, _, _ in camera:
            if img_head is None or img_depth is None:
                continue
            
            color = img_head.copy()
            depth = img_depth.astype(np.float32) / 1000.0
            
            logging.info("âœ“ è·å–åˆ°å›¾åƒï¼Œå¼€å§‹æ£€æµ‹...")
            
            # YOLOåˆ†å‰²
            results = yolo_model(color, verbose=False)
            
            if len(results) > 0 and results[0].masks is not None:
                masks = results[0].masks.data.cpu().numpy()
                
                if len(masks) > 0:
                    mask = masks[0]
                    if mask.shape != color.shape[:2]:
                        mask = cv2.resize(mask, (color.shape[1], color.shape[0]))
                    mask = (mask > 0.5).astype(bool)
                    
                    # FDPä½å§¿ä¼°è®¡
                    try:
                        logging.info("æ­£åœ¨è¿›è¡ŒFDPä½å§¿ä¼°è®¡...")
                        pose_result = est.register(K=K, rgb=color, depth=depth, ob_mask=mask, iteration=args.est_refine_iter)
                        
                        if isinstance(pose_result, tuple):
                            pose_in_camera = pose_result[0]
                        else:
                            pose_in_camera = pose_result
                        
                        pose_detected = True
                        
                        # æå–ä½å§¿ä¿¡æ¯ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
                        obj_pos_camera = pose_in_camera[:3, 3]
                        obj_rot_camera = pose_in_camera[:3, :3]
                        obj_quat_camera = Rotation.from_matrix(obj_rot_camera).as_quat()
                        euler_camera = Rotation.from_matrix(obj_rot_camera).as_euler('xyz', degrees=True)
                        
                        # è¾“å‡ºç»“æœ
                        print("\n" + "="*70)
                        print("ğŸ¯ FDPæ£€æµ‹åˆ°ç‰©ä½“ï¼")
                        print("="*70)
                        print(f"ğŸ“ ç›¸æœºåæ ‡ç³» (Camera Frame):")
                        print(f"   ä½ç½®: [{obj_pos_camera[0]:+.4f}, {obj_pos_camera[1]:+.4f}, {obj_pos_camera[2]:+.4f}] m")
                        print(f"   å››å…ƒæ•°: [{obj_quat_camera[0]:+.4f}, {obj_quat_camera[1]:+.4f}, {obj_quat_camera[2]:+.4f}, {obj_quat_camera[3]:+.4f}]")
                        print(f"   æ¬§æ‹‰è§’: Roll={euler_camera[0]:+7.2f}Â°, Pitch={euler_camera[1]:+7.2f}Â°, Yaw={euler_camera[2]:+7.2f}Â°")
                        print("="*70)
                        logging.info("âœ“ FDPä½å§¿ä¼°è®¡å®Œæˆï¼ˆç›¸æœºåæ ‡ç³»ï¼‰")
                        
                    except Exception as e:
                        logging.error(f"FDPä½å§¿ä¼°è®¡å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        pose_detected = False
                else:
                    logging.warning("YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“mask")
            else:
                logging.warning("YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“")
            
            # å¯è§†åŒ–
            vis = color.copy()
            
            if pose_detected:
                # ç»˜åˆ¶ç»¿è‰²3Dæ¡†
                center_pose = pose_in_camera @ np.linalg.inv(to_origin)
                vis = draw_posed_3d_box(K, img=vis, ob_in_cam=center_pose, bbox=bbox, linewidth=2)
                
                # ç»˜åˆ¶ä¸‰ä¸ªåæ ‡è½´ï¼ˆRGB: X=çº¢, Y=ç»¿, Z=è“ï¼‰
                vis = draw_xyz_axis(vis, ob_in_cam=center_pose, scale=0.1, K=K, thickness=3, transparency=0, is_input_rgb=True)
                
                cv2.putText(vis, "Detection Complete - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            else:
                cv2.putText(vis, "No object detected - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            # åªå¤„ç†ç¬¬ä¸€å¸§
            break
        
        return vis, pose_detected
    
    # ä¸»å¾ªç¯
    try:
        vis, pose_detected = detect_once()
        
        if vis is not None:
            cv2.imshow('FDP Monitor (Camera Frame)', vis[...,::-1])  # RGB to BGR
        
        logging.info("æ£€æµ‹å®Œæˆï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ...")
        while True:
            key = cv2.waitKey(100) & 0xFF
            
            if key == ord('q'):
                logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                break
            elif key == ord('r'):
                logging.info("é‡æ–°æ£€æµ‹ä¸­...")
                vis, pose_detected = detect_once()
                if vis is not None:
                    cv2.imshow('FDP Monitor (Camera Frame)', vis[...,::-1])
                    
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ä¸­æ–­")
    finally:
        cv2.destroyAllWindows()
        logging.info("ç¨‹åºç»“æŸ")

if __name__ == '__main__':
    main()
