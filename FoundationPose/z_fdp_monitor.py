#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çº¯FDPå®æ—¶ç›‘æµ‹è„šæœ¬ï¼ˆç›¸æœºåæ ‡ç³»ç‰ˆæœ¬ï¼‰
- ä½¿ç”¨æœºå™¨äººæ‘„åƒå¤´è¿›è¡Œå®æ—¶FDPæ£€æµ‹
- æ˜¾ç¤ºç»¿è‰²3Dæ¡†å’Œä¸‰ä¸ªåæ ‡è½´ï¼ˆRGBï¼‰
- è¾“å‡ºç›¸æœºåæ ‡ç³»ä¸‹çš„6Dä½å§¿ä¿¡æ¯
- ä¸è¿›è¡ŒåŸºåº§åæ ‡è½¬æ¢
- æ— æŠ“å–åŠŸèƒ½
"""

import os
import sys
import logging
import time
import json
import numpy as np
import cv2
from ultralytics import YOLO
from scipy.spatial.transform import Rotation
import trimesh
import nvdiffrast.torch as dr

from estimater import *
from Utils import *
from last import MMK2RealRobot

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='[%(levelname)s] %(message)s'
    )

def main():
    import argparse
    
    setup_logging()
    
    parser = argparse.ArgumentParser(description='FDPå®æ—¶ç›‘æµ‹ï¼ˆçº¯æ£€æµ‹ï¼Œæ— æŠ“å–ï¼Œä»…ç›¸æœºåæ ‡ï¼‰')
    code_dir = os.path.dirname(os.path.realpath(__file__))
    
    parser.add_argument('--robot_ip', type=str, required=False, default='192.168.11.200')
    
    # æ¨¡å‹å’Œæ•°æ®
    parser.add_argument('--mesh_file', type=str,
                       default=f'{code_dir}/demo_data/tube/mesh/1.obj')
    parser.add_argument('--yolo_model', type=str,
                       default=f'{code_dir}/10_30best.pt')
    
    # FDPå‚æ•°
    parser.add_argument('--est_refine_iter', type=int, default=10,
                       help='FDPæ³¨å†Œè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--head_pitch', type=float, default=-0.5236,
                       help='å¤´éƒ¨ä¿¯ä»°è§’åº¦ï¼ˆå¼§åº¦ï¼‰ï¼Œé»˜è®¤-30åº¦')
    
    args = parser.parse_args()
    
    print("="*70)
    print("ğŸ” FDPå®æ—¶ç›‘æµ‹ç³»ç»Ÿï¼ˆä»…ç›¸æœºåæ ‡ç³»ï¼‰")
    print("="*70)
    print(f"æœºå™¨äººIP: {args.robot_ip}")
    print(f"å¤´éƒ¨ä¿¯ä»°è§’: {np.degrees(args.head_pitch):.1f}Â° ({args.head_pitch:.4f} rad)")
    print("="*70 + "\n")
    
    logging.info("åˆå§‹åŒ–æœºå™¨äºº...")
    robot = MMK2RealRobot(ip=args.robot_ip)
    time.sleep(2.0)
    
    # è®¾ç½®å¤´éƒ¨è§’åº¦
    logging.info(f"è®¾ç½®å¤´éƒ¨è§’åº¦: {np.degrees(args.head_pitch):.1f}Â°")
    robot.set_robot_head_pose(0.0, args.head_pitch)
    time.sleep(1.0)
    
    # åŠ è½½æ¨¡å‹
    logging.info("åŠ è½½YOLOæ¨¡å‹...")
    yolo_model = YOLO(args.yolo_model)
    
    logging.info("åŠ è½½FoundationPose...")
    mesh = trimesh.load(args.mesh_file)
    to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
    bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)
    
    debug_dir = f'{code_dir}/debug'
    os.makedirs(debug_dir, exist_ok=True)
    
    scorer = ScorePredictor()
    refiner = PoseRefinePredictor()
    glctx = dr.RasterizeCudaContext()
    est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
                        mesh=mesh, scorer=scorer, refiner=refiner, 
                        glctx=glctx, debug_dir=debug_dir, debug=1)
    
    logging.info("âœ“ åˆå§‹åŒ–å®Œæˆ")
    logging.info("="*70)
    
    # ç›¸æœºå†…å‚
    K = np.array([[601.87, 0, 321.05], [0, 601.87, 252.46], [0, 0, 1]])
    camera = robot.camera
    time.sleep(2.0)
    
    print("\n" + "="*70)
    print("ğŸ” å¼€å§‹FDPæ£€æµ‹ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰")
    print("="*70)
    print("æç¤º: æŒ‰ 'r' é‡æ–°æ£€æµ‹, æŒ‰ 'q' é€€å‡ºç¨‹åº\n")
    
    def detect_once():
        """æ‰§è¡Œä¸€æ¬¡FDPæ£€æµ‹"""
        pose_detected = False
        pose_in_camera = None
        vis = None
        yolo_mask = None  # ä¿å­˜YOLO maskç”¨äºå¯è§†åŒ–
        
        logging.info("æ­£åœ¨è·å–å›¾åƒ...")
        for img_head, img_depth, _, _ in camera:
            if img_head is None or img_depth is None:
                continue
            
            color = img_head.copy()
            depth = img_depth.astype(np.float32) / 1000.0
            
            logging.info("âœ“ è·å–åˆ°å›¾åƒï¼Œå¼€å§‹æ£€æµ‹...")
            
            # YOLOåˆ†å‰²
            results = yolo_model(color, verbose=False)
            
            if len(results) > 0 and results[0].masks is not None:
                masks = results[0].masks.data.cpu().numpy()
                
                if len(masks) > 0:
                    mask = masks[0]
                    if mask.shape != color.shape[:2]:
                        mask = cv2.resize(mask, (color.shape[1], color.shape[0]))
                    mask = (mask > 0.5).astype(bool)
                    yolo_mask = mask  # ä¿å­˜maskç”¨äºå¯è§†åŒ–
                    
                    # FDPä½å§¿ä¼°è®¡
                    try:
                        logging.info("æ­£åœ¨è¿›è¡ŒFDPä½å§¿ä¼°è®¡...")
                        pose_result = est.register(K=K, rgb=color, depth=depth, ob_mask=mask, iteration=args.est_refine_iter)
                        
                        if isinstance(pose_result, tuple):
                            pose_in_camera = pose_result[0]
                        else:
                            pose_in_camera = pose_result
                        
                        pose_detected = True
                        
                        # æå–ä½å§¿ä¿¡æ¯ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
                        obj_pos_camera = pose_in_camera[:3, 3]
                        obj_rot_camera = pose_in_camera[:3, :3]
                        obj_quat_camera = Rotation.from_matrix(obj_rot_camera).as_quat()
                        euler_camera = Rotation.from_matrix(obj_rot_camera).as_euler('xyz', degrees=True)
                        
                        # è¾“å‡ºç»“æœ
                        print("\n" + "="*70)
                        print("ğŸ¯ FDPæ£€æµ‹åˆ°ç‰©ä½“ï¼")
                        print("="*70)
                        print(f"ğŸ“ ç›¸æœºåæ ‡ç³» (Camera Frame):")
                        print(f"   ä½ç½®: [{obj_pos_camera[0]:+.4f}, {obj_pos_camera[1]:+.4f}, {obj_pos_camera[2]:+.4f}] m")
                        print(f"   å››å…ƒæ•°: [{obj_quat_camera[0]:+.4f}, {obj_quat_camera[1]:+.4f}, {obj_quat_camera[2]:+.4f}, {obj_quat_camera[3]:+.4f}]")
                        print(f"   æ¬§æ‹‰è§’: Roll={euler_camera[0]:+7.2f}Â°, Pitch={euler_camera[1]:+7.2f}Â°, Yaw={euler_camera[2]:+7.2f}Â°")
                        print("\nğŸ“Š ç›¸æœºåæ ‡ç³»å˜æ¢çŸ©é˜µ (4Ã—4):")
                        print(f"   [{pose_in_camera[0,0]:+.6f}, {pose_in_camera[0,1]:+.6f}, {pose_in_camera[0,2]:+.6f}, {pose_in_camera[0,3]:+.6f}]")
                        print(f"   [{pose_in_camera[1,0]:+.6f}, {pose_in_camera[1,1]:+.6f}, {pose_in_camera[1,2]:+.6f}, {pose_in_camera[1,3]:+.6f}]")
                        print(f"   [{pose_in_camera[2,0]:+.6f}, {pose_in_camera[2,1]:+.6f}, {pose_in_camera[2,2]:+.6f}, {pose_in_camera[2,3]:+.6f}]")
                        print(f"   [{pose_in_camera[3,0]:+.6f}, {pose_in_camera[3,1]:+.6f}, {pose_in_camera[3,2]:+.6f}, {pose_in_camera[3,3]:+.6f}]")
                        
                        # è®¡ç®—å¹¶æ˜¾ç¤ºYOLOä¸FDPä¸­å¿ƒçš„åç§»ï¼ˆç”¨äºåˆ¤æ–­å‡†ç¡®æ€§ï¼‰
                        if yolo_mask is not None:
                            mask_uint8 = (mask * 255).astype(np.uint8)
                            moments = cv2.moments(mask_uint8)
                            if moments['m00'] > 0:
                                yolo_cx = int(moments['m10'] / moments['m00'])
                                yolo_cy = int(moments['m01'] / moments['m00'])
                                
                                # è®¡ç®—FDPä¸­å¿ƒæŠ•å½±
                                fdp_2d = K @ pose_in_camera[:3, 3]
                                fdp_2d = fdp_2d / fdp_2d[2]
                                fdp_cx, fdp_cy = int(fdp_2d[0]), int(fdp_2d[1])
                                
                                # è®¡ç®—åƒç´ åç§»
                                offset_x = fdp_cx - yolo_cx
                                offset_y = fdp_cy - yolo_cy
                                offset_total = np.sqrt(offset_x**2 + offset_y**2)
                                
                                print(f"\nğŸ” æ£€æµ‹è´¨é‡åˆ†æ:")
                                print(f"   YOLOä¸­å¿ƒ: ({yolo_cx}, {yolo_cy}) åƒç´ ")
                                print(f"   FDPä¸­å¿ƒ:  ({fdp_cx}, {fdp_cy}) åƒç´ ")
                                print(f"   åƒç´ åç§»: Î”x={offset_x:+d}, Î”y={offset_y:+d}, æ€»åç§»={offset_total:.1f}åƒç´ ")
                                if offset_total < 20:
                                    print(f"   âœ“ åç§»è¾ƒå°ï¼ŒFDPæ£€æµ‹å‡†ç¡®")
                                elif offset_total < 50:
                                    print(f"   âš  åç§»ä¸­ç­‰ï¼ŒFDPå¯èƒ½ç•¥æœ‰åå·®")
                                else:
                                    print(f"   âœ— åç§»è¾ƒå¤§ï¼ŒFDPæ£€æµ‹å¯èƒ½ä¸å‡†ç¡®ï¼")
                        
                        print("="*70)
                        logging.info("âœ“ FDPä½å§¿ä¼°è®¡å®Œæˆï¼ˆç›¸æœºåæ ‡ç³»ï¼‰")
                        
                    except Exception as e:
                        logging.error(f"FDPä½å§¿ä¼°è®¡å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        pose_detected = False
                else:
                    logging.warning("YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“mask")
            else:
                logging.warning("YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“")
            
            # å¯è§†åŒ–
            vis = color.copy()
            
            # 1. ç»˜åˆ¶YOLOåˆ†å‰²maskï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if yolo_mask is not None:
                # åŠé€æ˜è“è‰²é®ç½©
                mask_overlay = vis.copy()
                mask_overlay[yolo_mask] = (100, 200, 255)  # æµ…è“è‰²
                vis = cv2.addWeighted(mask_overlay, 0.3, vis, 0.7, 0)
                
                # é»„è‰²è½®å»“çº¿ï¼ˆç»†ï¼‰
                mask_uint8 = (yolo_mask * 255).astype(np.uint8)
                contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(vis, contours, -1, (0, 255, 255), 1)  # çº¿å®½æ”¹ä¸º1
                
                # YOLO maskä¸­å¿ƒç‚¹
                moments = cv2.moments(mask_uint8)
                if moments['m00'] > 0:
                    mask_cx = int(moments['m10'] / moments['m00'])
                    mask_cy = int(moments['m01'] / moments['m00'])
                    cv2.circle(vis, (mask_cx, mask_cy), 5, (0, 0, 255), -1)  # çº¢è‰²åœ†ç‚¹ï¼ˆæ›´å°ï¼‰
                    cv2.circle(vis, (mask_cx, mask_cy), 7, (255, 255, 255), 1)  # ç™½è‰²å¤–åœˆï¼ˆæ›´ç»†ï¼‰
                    cv2.putText(vis, "YOLO", (mask_cx + 10, mask_cy - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)  # å­—ä½“æ›´å°
            
            # 2. ç»˜åˆ¶FDPæ£€æµ‹ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if pose_detected:
                # ç»˜åˆ¶ç»¿è‰²3Dæ¡†ï¼ˆç»†çº¿ï¼‰
                center_pose = pose_in_camera @ np.linalg.inv(to_origin)
                vis = draw_posed_3d_box(K, img=vis, ob_in_cam=center_pose, bbox=bbox, linewidth=1)  # çº¿å®½æ”¹ä¸º1
                
                # ç»˜åˆ¶ä¸‰ä¸ªåæ ‡è½´ï¼ˆç»†çº¿ï¼‰
                vis = draw_xyz_axis(vis, ob_in_cam=center_pose, scale=0.1, K=K, thickness=2, transparency=0, is_input_rgb=True)  # thicknessæ”¹ä¸º2
                
                # FDPä¸­å¿ƒç‚¹
                obj_2d = K @ pose_in_camera[:3, 3]
                obj_2d = obj_2d / obj_2d[2]
                fdp_cx, fdp_cy = int(obj_2d[0]), int(obj_2d[1])
                if 0 <= fdp_cx < vis.shape[1] and 0 <= fdp_cy < vis.shape[0]:
                    cv2.drawMarker(vis, (fdp_cx, fdp_cy), (255, 0, 255), cv2.MARKER_CROSS, 15, 2)  # æ›´å°çš„åå­—
                    cv2.putText(vis, "FDP", (fdp_cx + 10, fdp_cy + 15),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 1)  # å­—ä½“æ›´å°
                
                cv2.putText(vis, "Detection Complete - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            else:
                cv2.putText(vis, "No object detected - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            # åªå¤„ç†ç¬¬ä¸€å¸§
            break
        
        return vis, pose_detected
    
    # ä¸»å¾ªç¯
    try:
        vis, pose_detected = detect_once()
        
        if vis is not None:
            cv2.imshow('FDP Monitor (Camera Frame)', vis[...,::-1])  # RGB to BGR
        
        logging.info("æ£€æµ‹å®Œæˆï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ...")
        while True:
            key = cv2.waitKey(100) & 0xFF
            
            if key == ord('q'):
                logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                break
            elif key == ord('r'):
                logging.info("é‡æ–°æ£€æµ‹ä¸­...")
                vis, pose_detected = detect_once()
                if vis is not None:
                    cv2.imshow('FDP Monitor (Camera Frame)', vis[...,::-1])
                    
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ä¸­æ–­")
    finally:
        cv2.destroyAllWindows()
        logging.info("ç¨‹åºç»“æŸ")

if __name__ == '__main__':
    main()
