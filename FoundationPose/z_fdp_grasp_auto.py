#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–è„šæœ¬
- ä½¿ç”¨FDPæ£€æµ‹è·å–ç‰©ä½“xyzä½ç½®ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
- è‡ªåŠ¨æ‰§è¡ŒæŠ“å–æµç¨‹ï¼ˆåæ ‡å˜æ¢ + æŠ“å–åŠ¨ä½œï¼‰
- ä¿æŒoperator_process_1029.pyçš„çŸ©é˜µå’Œå‚æ•°ä¸å˜
"""

import os
import sys
import logging
import time
import numpy as np
import cv2
from ultralytics import YOLO
from scipy.spatial.transform import Rotation
import trimesh
import nvdiffrast.torch as dr

from estimater import *
from Utils import *
from last import MMK2RealRobot

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='[%(levelname)s] %(message)s'
    )

def transform_point(point_camera, transform_matrix):
    """
    å°†ç‚¹ä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°åŸºåº§åæ ‡ç³»
    :param point_camera: [x, y, z] in camera frame
    :param transform_matrix: 4x4 matrix
    :return: [x, y, z] in base_link frame
    """
    # è½¬æˆé½æ¬¡åæ ‡
    p_cam = np.array([*point_camera, 1.0])
    # è®¡ç®—å˜æ¢
    p_base = transform_matrix @ p_cam
    # è¿”å›å‰ä¸‰ä¸ªåˆ†é‡
    return p_base[:3]

def main():
    import argparse
    
    setup_logging()
    
    parser = argparse.ArgumentParser(description='FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–')
    code_dir = os.path.dirname(os.path.realpath(__file__))
    
    parser.add_argument('--robot_ip', type=str, default='192.168.11.200')
    parser.add_argument('--mesh_file', type=str,
                       default=f'{code_dir}/demo_data/tube/mesh/1.obj')
    parser.add_argument('--yolo_model', type=str,
                       default=f'{code_dir}/10_30best.pt')
    
    # FDPå‚æ•°
    parser.add_argument('--est_refine_iter', type=int, default=10,
                       help='FDPæ³¨å†Œè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--head_pitch', type=float, default=-0.5236,
                       help='å¤´éƒ¨ä¿¯ä»°è§’åº¦ï¼ˆå¼§åº¦ï¼‰ï¼Œé»˜è®¤-30åº¦')
    
    args = parser.parse_args()
    
    print("="*70)
    print("ğŸ¤– FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–ç³»ç»Ÿ")
    print("="*70)
    print(f"æœºå™¨äººIP: {args.robot_ip}")
    print(f"å¤´éƒ¨è§’åº¦: {np.degrees(args.head_pitch):.1f}Â°")
    print("="*70 + "\n")
    
    # ============ 1. åˆå§‹åŒ–æœºå™¨äºº ============
    logging.info("åˆå§‹åŒ–æœºå™¨äºº...")
    mmk2 = MMK2RealRobot(ip=args.robot_ip)
    time.sleep(2.0)
    
    # è®¾ç½®å¤´éƒ¨è§’åº¦
    logging.info(f"è®¾ç½®å¤´éƒ¨è§’åº¦: {np.degrees(args.head_pitch):.1f}Â°")
    mmk2.set_robot_head_pose(0.0, args.head_pitch)
    time.sleep(1.0)
    
    # ============ 2. åŠ è½½æ¨¡å‹ ============
    logging.info("åŠ è½½YOLOæ¨¡å‹...")
    yolo_model = YOLO(args.yolo_model)
    
    logging.info("åŠ è½½FoundationPose...")
    mesh = trimesh.load(args.mesh_file)
    to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
    bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)
    
    debug_dir = f'{code_dir}/debug'
    os.makedirs(debug_dir, exist_ok=True)
    
    scorer = ScorePredictor()
    refiner = PoseRefinePredictor()
    glctx = dr.RasterizeCudaContext()
    est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
                        mesh=mesh, scorer=scorer, refiner=refiner, 
                        glctx=glctx, debug_dir=debug_dir, debug=1)
    
    logging.info("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # ç›¸æœºå†…å‚
    K = np.array([[601.87, 0, 321.05], [0, 601.87, 252.46], [0, 0, 1]])
    camera = mmk2.camera
    time.sleep(2.0)
    
    # åˆ›å»ºæ˜¾ç¤ºçª—å£
    cv2.namedWindow('FDP Auto Grasp - Detection', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('FDP Auto Grasp - Detection', 640, 480)
    
    # ============ 3. ä¸»å¾ªç¯ï¼šæ£€æµ‹å’ŒæŠ“å– ============
    print("\n" + "="*70)
    print("ğŸ” FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–ç³»ç»Ÿ")
    print("="*70)
    print("æç¤º: æŒ‰ 'g' å¼€å§‹æŠ“å–, æŒ‰ 'r' é‡æ–°æ£€æµ‹, æŒ‰ 'q' é€€å‡º")
    print("="*70 + "\n")
    
    # åˆå§‹ä½ç½®å’ŒæŠ“å–å§¿æ€ï¼ˆä¿æŒä¸å˜ï¼‰
    init_pose = [0.4798196384291117, 0.050344892205700036, 1.3300944085789266,
                 0.004922124603778732, -0.003476176971870248, -0.6913608163682425, 0.7224845399547885]
    
    grasp_rot = [0.09538087446650391, 0.019704521010289917, -0.5310926713809747, 0.8416975674452077]
    
    # å˜æ¢çŸ©é˜µï¼ˆä¿æŒä¸å˜ï¼‰
    T_head_to_base = np.array([
        [-0.001, -0.749, 0.662, 0.365],
        [-1.000, 0.001, -0.001, 0.036],
        [-0.000, -0.662, -0.749, 1.516],
        [0.000, 0.000, 0.000, 1.000],
    ])
    
    T_left_arm_to_base = np.array([
        [0.042, 0.999, -0.012, 0.480],
        [-0.999, 0.042, 0.004, 0.050],
        [0.005, 0.012, 1.000, 1.330],
        [0.000, 0.000, 0.000, 1.000],
    ])
    
    def detect_fdp():
        """æ‰§è¡ŒFDPæ£€æµ‹ï¼Œè¿”å›æ£€æµ‹åˆ°çš„xyzä½ç½®"""
        logging.info("å¼€å§‹FDPæ£€æµ‹...")
        
        for img_head, img_depth, _, _ in camera:
            if img_head is None or img_depth is None:
                continue
            
            color = img_head.copy()
            depth = img_depth.astype(np.float32) / 1000.0
            
            logging.info("âœ“ è·å–åˆ°å›¾åƒ")
            
            # YOLOåˆ†å‰²
            results = yolo_model(color, verbose=False)
            
            if len(results) == 0 or results[0].masks is None:
                logging.warning("âŒ YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“")
                return None, None
            
            masks = results[0].masks.data.cpu().numpy()
            if len(masks) == 0:
                logging.warning("âŒ YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“mask")
                return None, None
            
            mask = masks[0]
            if mask.shape != color.shape[:2]:
                mask = cv2.resize(mask, (color.shape[1], color.shape[0]))
            mask = (mask > 0.5).astype(bool)
            
            logging.info("âœ“ YOLOæ£€æµ‹æˆåŠŸ")
            
            # FDPä½å§¿ä¼°è®¡
            try:
                logging.info("æ­£åœ¨è¿›è¡ŒFDPä½å§¿ä¼°è®¡...")
                pose_result = est.register(K=K, rgb=color, depth=depth, ob_mask=mask, 
                                          iteration=args.est_refine_iter)
                
                if isinstance(pose_result, tuple):
                    pose_in_camera = pose_result[0]
                else:
                    pose_in_camera = pose_result
                
                # æå–ç‰©ä½“åœ¨ç›¸æœºåæ ‡ç³»çš„ä½ç½®ï¼ˆåªå–xyzï¼‰
                point_fdp_camera_xyz = pose_in_camera[:3, 3].tolist()
                
                print("\n" + "="*70)
                print("ğŸ¯ FDPæ£€æµ‹æˆåŠŸï¼")
                print("="*70)
                print(f"ğŸ“ ç›¸æœºåæ ‡ç³»ä½ç½®: [{point_fdp_camera_xyz[0]:+.4f}, {point_fdp_camera_xyz[1]:+.4f}, {point_fdp_camera_xyz[2]:+.4f}] m")
                print("="*70)
                
                logging.info("âœ“ FDPä½å§¿ä¼°è®¡å®Œæˆ")
                
                # å¯è§†åŒ–ï¼šåªæ˜¾ç¤ºç»¿è‰²3Dæ¡†å’Œåæ ‡è½´
                vis = color.copy()
                
                # ç»˜åˆ¶ç»¿è‰²3Dæ¡†
                center_pose = pose_in_camera @ np.linalg.inv(to_origin)
                vis = draw_posed_3d_box(K, img=vis, ob_in_cam=center_pose, bbox=bbox, linewidth=1)
                
                # ç»˜åˆ¶ä¸‰ä¸ªåæ ‡è½´ï¼ˆRGB: X=çº¢, Y=ç»¿, Z=è“ï¼‰
                vis = draw_xyz_axis(vis, ob_in_cam=center_pose, scale=0.1, K=K, thickness=1, transparency=0, is_input_rgb=True)
                
                # æ˜¾ç¤ºçŠ¶æ€æ–‡æœ¬
                cv2.putText(vis, "Press 'g' to grasp, 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])  # RGB to BGR
                cv2.waitKey(1)
                
                return point_fdp_camera_xyz, vis
                
            except Exception as e:
                logging.error(f"âŒ FDPä½å§¿ä¼°è®¡å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None, None
            
            # åªå¤„ç†ç¬¬ä¸€å¸§
            break
        
        return None, None
    
    def execute_grasp(point_fdp_camera_xyz):
        """æ‰§è¡ŒæŠ“å–æµç¨‹"""
        print("\n" + "="*70)
        print("ğŸ¤– å¼€å§‹æ‰§è¡ŒæŠ“å–æµç¨‹...")
        print("="*70)
        
        # åæ ‡å˜æ¢ï¼šç›¸æœº â†’ åŸºåº§
        point_prepare_base_xyz = transform_point(point_fdp_camera_xyz, T_head_to_base)
        logging.info(f"åŸºåº§åæ ‡ç³»ä½ç½®: [{point_prepare_base_xyz[0]:+.4f}, {point_prepare_base_xyz[1]:+.4f}, {point_prepare_base_xyz[2]:+.4f}] m")
        
        # åæ ‡å˜æ¢ï¼šåŸºåº§ â†’ å·¦è‡‚æœ«ç«¯
        point_fdp_left_arm_xyz = transform_point(point_prepare_base_xyz, np.linalg.inv(T_left_arm_to_base))
        
        # åœ¨å·¦è‡‚åæ ‡ç³»ä¸‹è°ƒæ•´ä½ç½®ï¼ˆå‡†å¤‡ä½ç½®ï¼šç‰©ä½“ä¸Šæ–¹15cmï¼ŒYæ–¹å‘åç§»2cmï¼‰
        point_fdp_left_arm_xyz[2] += 0.15  # Zæ–¹å‘å‘ä¸Š15cm
        point_fdp_left_arm_xyz[1] += 0.02  # Yæ–¹å‘åç§»2cm
        
        # è½¬æ¢å›åŸºåº§åæ ‡ç³»
        point_prepare_base_xyz = transform_point(point_fdp_left_arm_xyz, T_left_arm_to_base)
        print(f"\nå‡†å¤‡ä½ç½®ï¼ˆåŸºåº§ï¼‰: [{point_prepare_base_xyz[0]:+.4f}, {point_prepare_base_xyz[1]:+.4f}, {point_prepare_base_xyz[2]:+.4f}] m")
        
        # æ­¥éª¤1ï¼šç§»åŠ¨åˆ°å‡†å¤‡ä½ç½®
        logging.info("[1/5] ç§»åŠ¨åˆ°å‡†å¤‡ä½ç½®ï¼ˆç‰©ä½“ä¸Šæ–¹15cmï¼‰...")
        mmk2.set_robot_eef('left_arm', 1)  # æ‰“å¼€å¤¹çˆª
        point_prepare_base = list(point_prepare_base_xyz) + list(grasp_rot)
        mmk2.control_arm_pose('left_arm', point_prepare_base)
        time.sleep(2.0)
        
        # æ­¥éª¤2ï¼šä¸‹é™åˆ°æŠ“å–ä½ç½®
        logging.info("[2/5] ä¸‹é™åˆ°æŠ“å–ä½ç½®ï¼ˆç‰©ä½“ä¸Šæ–¹6cmï¼‰...")
        point_prepare_left_arm_xyz = transform_point(point_prepare_base_xyz, np.linalg.inv(T_left_arm_to_base))
        point_prepare_left_arm_xyz[2] -= 0.09  # Zæ–¹å‘ä¸‹é™9cm (15cm - 9cm = 6cm)
        
        point_grasp_base_xyz = transform_point(point_prepare_left_arm_xyz, T_left_arm_to_base)
        print(f"æŠ“å–ä½ç½®ï¼ˆåŸºåº§ï¼‰: [{point_grasp_base_xyz[0]:+.4f}, {point_grasp_base_xyz[1]:+.4f}, {point_grasp_base_xyz[2]:+.4f}] m")
        
        point_grasp_base = list(point_grasp_base_xyz) + list(grasp_rot)
        mmk2.control_arm_pose('left_arm', point_grasp_base)
        time.sleep(2.0)
        
        # æ­¥éª¤3ï¼šæ‰“å¼€å¤¹çˆªæŠ“å–
        logging.info("[3/5] æ‰“å¼€å¤¹çˆª...")
        mmk2.set_robot_eef('left_arm', 0)  # å…³é—­å¤¹çˆª
        time.sleep(1.5)
        
        # æ­¥éª¤4ï¼šè¿”å›åˆ°å‡†å¤‡ä½ç½®
        logging.info("[4/5] è¿”å›åˆ°å‡†å¤‡ä½ç½®...")
        mmk2.control_arm_pose('left_arm', point_prepare_base)
        time.sleep(2.0)
        
        # æ­¥éª¤5ï¼šè¿”å›åˆ°åˆå§‹ä½ç½®
        logging.info("[5/5] è¿”å›åˆ°åˆå§‹ä½ç½®...")
        mmk2.control_arm_pose('left_arm', init_pose)
        time.sleep(2.0)
        mmk2.set_robot_eef('left_arm', 1)  # æ‰“å¼€å¤¹çˆª
        mmk2.set_robot_eef('left_arm', 0)  # å…³é—­å¤¹çˆª
        
        print("\n" + "="*70)
        print("âœ… æŠ“å–æµç¨‹å®Œæˆï¼")
        print("="*70)
        print("æç¤º: æŒ‰ 'r' é‡æ–°æ£€æµ‹, æŒ‰ 'q' é€€å‡º")
    
    # ä¸»å¾ªç¯
    point_fdp_camera_xyz = None
    vis = None
    
    while True:
        # æ‰§è¡ŒFDPæ£€æµ‹
        point_fdp_camera_xyz, vis = detect_fdp()
        
        if point_fdp_camera_xyz is None:
            logging.warning("âŒ æ£€æµ‹å¤±è´¥ï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ...")
            # æ˜¾ç¤ºé”™è¯¯æç¤º
            if vis is not None:
                cv2.putText(vis, "Detection Failed - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])
            
            # ç­‰å¾…ç”¨æˆ·æŒ‰é”®
            while True:
                key = cv2.waitKey(100) & 0xFF
                if key == ord('q'):
                    logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                    cv2.destroyAllWindows()
                    return
                elif key == ord('r'):
                    logging.info("é‡æ–°æ£€æµ‹...")
                    break
            continue
        
        # ç­‰å¾…ç”¨æˆ·æŒ‰é”®ï¼ˆæ£€æµ‹æˆåŠŸï¼‰
        while True:
            key = cv2.waitKey(100) & 0xFF
            if key == ord('q'):
                logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                cv2.destroyAllWindows()
                return
            elif key == ord('g'):
                execute_grasp(point_fdp_camera_xyz)
                # æŠ“å–å®Œæˆåï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ
                while True:
                    key = cv2.waitKey(100) & 0xFF
                    if key == ord('q'):
                        logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                        cv2.destroyAllWindows()
                        return
                    elif key == ord('r'):
                        logging.info("é‡æ–°æ£€æµ‹...")
                        break
                break
            elif key == ord('r'):
                logging.info("é‡æ–°æ£€æµ‹...")
                break

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ä¸­æ–­")
        cv2.destroyAllWindows()
    except Exception as e:
        logging.error(f"ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        cv2.destroyAllWindows()

