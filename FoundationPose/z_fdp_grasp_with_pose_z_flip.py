#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–è„šæœ¬ï¼ˆä½¿ç”¨FDPå®Œæ•´ä½å§¿å¯¹é½æŠ“å–ï¼‰
- ä½¿ç”¨FDPæ£€æµ‹è·å–ç‰©ä½“å®Œæ•´ä½å§¿ï¼ˆä½ç½®+å§¿æ€ï¼Œç›¸æœºåæ ‡ç³»ï¼‰
- å®æ—¶è¯»å–å¤´éƒ¨åˆ°åŸºåº§å’Œæœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ
- æŒ‰ç…§FDPæ£€æµ‹çš„å®Œæ•´ä½å§¿è¿›è¡Œå¯¹é½å¹¶æŠ“å–
- é¿å…æœºæ¢°è‡‚è½¬åˆ°åˆ«æ‰­çš„è§’åº¦å¯¼è‡´å¡æ­»
"""

import os
import sys
import logging
import time
import numpy as np
import cv2
import subprocess
import re
from ultralytics import YOLO
from scipy.spatial.transform import Rotation
import trimesh
import nvdiffrast.torch as dr

from estimater import *
from Utils import *
from last import MMK2RealRobot

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='[%(levelname)s] %(message)s'
    )

def transform_point(point_camera, transform_matrix):
    """
    å°†ç‚¹ä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°åŸºåº§åæ ‡ç³»
    :param point_camera: [x, y, z] in camera frame
    :param transform_matrix: 4x4 matrix
    :return: [x, y, z] in base_link frame
    """
    # è½¬æˆé½æ¬¡åæ ‡
    p_cam = np.array([*point_camera, 1.0])
    # è®¡ç®—å˜æ¢
    p_base = transform_matrix @ p_cam
    # è¿”å›å‰ä¸‰ä¸ªåˆ†é‡
    return p_base[:3]

def transform_quaternion(quat, T):
    """
    å°†å››å…ƒæ•°ï¼ˆå§¿æ€ï¼‰ä»å±€éƒ¨åæ ‡ç³»è½¬æ¢åˆ°å¦ä¸€ä¸ªåæ ‡ç³»
    :param quat: list æˆ– np.ndarray, å››å…ƒæ•° [x, y, z, w]
    :param T: np.ndarray, 4x4 é½æ¬¡å˜æ¢çŸ©é˜µ
    :return: new_quat: np.ndarray, è½¬æ¢åçš„å››å…ƒæ•° [x, y, z, w]
    """
    # æå–æ—‹è½¬çŸ©é˜µéƒ¨åˆ†
    R_transform = T[:3, :3]
    # åŸå››å…ƒæ•°å¯¹åº”çš„æ—‹è½¬çŸ©é˜µ
    R_original = Rotation.from_quat(quat).as_matrix()
    # è½¬æ¢åçš„æ—‹è½¬çŸ©é˜µ
    R_transformed = R_transform @ R_original
    # è½¬ä¸ºå››å…ƒæ•°
    new_quat = Rotation.from_matrix(R_transformed).as_quat()
    return new_quat

def get_tf_transform(target_frame, source_frame, timeout=5.0):
    """
    é€šè¿‡ROS2 TFè·å–å˜æ¢çŸ©é˜µ
    :param target_frame: ç›®æ ‡åæ ‡ç³»ï¼ˆå¦‚ 'base_link'ï¼‰
    :param source_frame: æºåæ ‡ç³»ï¼ˆå¦‚ 'head_camera_link'ï¼‰
    :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :return: 4x4 å˜æ¢çŸ©é˜µ (target_frame <- source_frame)ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        # è°ƒç”¨ ros2 run tf2_ros tf2_echo å‘½ä»¤
        cmd = ['ros2', 'run', 'tf2_ros', 'tf2_echo', target_frame, source_frame]
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            timeout=timeout,
            stderr=subprocess.PIPE
        )
        
        if result.returncode != 0:
            logging.warning(f"TFå˜æ¢è·å–å¤±è´¥: {result.stderr}")
            return None
        
        # è§£æè¾“å‡ºï¼Œæå–å˜æ¢çŸ©é˜µ
        output = result.stdout + result.stderr
        lines = output.split('\n')
        
        # æŸ¥æ‰¾å¹³ç§»éƒ¨åˆ†
        translation = None
        rotation = None
        
        for i, line in enumerate(lines):
            # æŸ¥æ‰¾å¹³ç§»: x, y, z
            if 'Translation:' in line or 'translation:' in line:
                # æå– x, y, z å€¼
                trans_match = re.search(r'x:\s*([-+]?\d+\.?\d*),\s*y:\s*([-+]?\d+\.?\d*),\s*z:\s*([-+]?\d+\.?\d*)', output)
                if trans_match:
                    translation = [float(trans_match.group(1)), 
                                 float(trans_match.group(2)), 
                                 float(trans_match.group(3))]
            
            # æŸ¥æ‰¾æ—‹è½¬: x, y, z, w
            if 'Rotation:' in line or 'rotation:' in line:
                # æå– x, y, z, w å€¼
                rot_match = re.search(r'x:\s*([-+]?\d+\.?\d*),\s*y:\s*([-+]?\d+\.?\d*),\s*z:\s*([-+]?\d+\.?\d*),\s*w:\s*([-+]?\d+\.?\d*)', output)
                if rot_match:
                    rotation = [float(rot_match.group(1)), 
                              float(rot_match.group(2)), 
                              float(rot_match.group(3)), 
                              float(rot_match.group(4))]
        
        # å¦‚æœæ‰¾åˆ°äº†å¹³ç§»å’Œæ—‹è½¬ï¼Œæ„å»ºå˜æ¢çŸ©é˜µ
        if translation is not None and rotation is not None:
            T = np.eye(4)
            # è®¾ç½®å¹³ç§»
            T[:3, 3] = translation
            # è®¾ç½®æ—‹è½¬ï¼ˆå››å…ƒæ•°è½¬æ—‹è½¬çŸ©é˜µï¼‰
            R_rot = Rotation.from_quat(rotation).as_matrix()
            T[:3, :3] = R_rot
            return T
        else:
            logging.warning(f"æ— æ³•è§£æTFè¾“å‡º: {output[:200]}")
            return None
            
    except subprocess.TimeoutExpired:
        logging.warning(f"è·å–TFå˜æ¢è¶…æ—¶: {target_frame} <- {source_frame}")
        return None
    except Exception as e:
        logging.warning(f"è·å–TFå˜æ¢æ—¶å‡ºé”™: {e}")
        return None

def pose_to_matrix(position, quaternion):
    """
    å°†ä½ç½®å’Œå››å…ƒæ•°è½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µ
    :param position: [x, y, z]
    :param quaternion: [qx, qy, qz, qw]
    :return: 4x4 å˜æ¢çŸ©é˜µ
    """
    T = np.eye(4)
    T[:3, 3] = position
    T[:3, :3] = Rotation.from_quat(quaternion).as_matrix()
    return T

def main():
    import argparse
    
    setup_logging()
    
    parser = argparse.ArgumentParser(description='FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–ï¼ˆä½¿ç”¨FDPå®Œæ•´ä½å§¿å¯¹é½æŠ“å–ï¼‰')
    code_dir = os.path.dirname(os.path.realpath(__file__))
    
    parser.add_argument('--robot_ip', type=str, default='192.168.11.200')
    parser.add_argument('--mesh_file', type=str,
                       default=f'{code_dir}/demo_data/tube/mesh/1.obj')
    parser.add_argument('--yolo_model', type=str,
                       default=f'{code_dir}/10_30best.pt')
    
    # FDPå‚æ•°
    parser.add_argument('--est_refine_iter', type=int, default=10,
                       help='FDPæ³¨å†Œè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--head_pitch', type=float, default=-0.5236,
                       help='å¤´éƒ¨ä¿¯ä»°è§’åº¦ï¼ˆå¼§åº¦ï¼‰ï¼Œé»˜è®¤-30åº¦')
    
    args = parser.parse_args()
    
    print("="*70)
    print("ğŸ¤– FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–ç³»ç»Ÿï¼ˆä½¿ç”¨FDPå®Œæ•´ä½å§¿å¯¹é½æŠ“å–ï¼‰")
    print("="*70)
    print(f"æœºå™¨äººIP: {args.robot_ip}")
    print(f"å¤´éƒ¨è§’åº¦: {np.degrees(args.head_pitch):.1f}Â°")
    print("="*70 + "\n")
    
    # ============ 1. åˆå§‹åŒ–æœºå™¨äºº ============
    logging.info("åˆå§‹åŒ–æœºå™¨äºº...")
    mmk2 = MMK2RealRobot(ip=args.robot_ip)
    time.sleep(2.0)
    
    # è®¾ç½®å¤´éƒ¨è§’åº¦
    logging.info(f"è®¾ç½®å¤´éƒ¨è§’åº¦: {np.degrees(args.head_pitch):.1f}Â°")
    mmk2.set_robot_head_pose(0.0, args.head_pitch)
    time.sleep(1.0)
    
    # ============ 2. åŠ è½½æ¨¡å‹ ============
    logging.info("åŠ è½½YOLOæ¨¡å‹...")
    yolo_model = YOLO(args.yolo_model)
    
    logging.info("åŠ è½½FoundationPose...")
    mesh = trimesh.load(args.mesh_file)
    to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
    bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)
    
    debug_dir = f'{code_dir}/debug'
    os.makedirs(debug_dir, exist_ok=True)
    
    scorer = ScorePredictor()
    refiner = PoseRefinePredictor()
    glctx = dr.RasterizeCudaContext()
    est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
                        mesh=mesh, scorer=scorer, refiner=refiner, 
                        glctx=glctx, debug_dir=debug_dir, debug=1)
    
    logging.info("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # ç›¸æœºå†…å‚
    K = np.array([[601.87, 0, 321.05], [0, 601.87, 252.46], [0, 0, 1]])
    camera = mmk2.camera
    time.sleep(2.0)
    
    # åˆ›å»ºæ˜¾ç¤ºçª—å£
    cv2.namedWindow('FDP Auto Grasp - Detection', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('FDP Auto Grasp - Detection', 640, 480)
    
    # ============ 3. è·å–å®æ—¶å˜æ¢çŸ©é˜µ ============
    print("\n" + "="*70)
    print("ğŸ“ è·å–å®æ—¶å˜æ¢çŸ©é˜µ...")
    print("="*70)
    
    # å®æ—¶è·å–å¤´éƒ¨åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ (base_link <- head_camera_link)
    logging.info("è·å–å¤´éƒ¨åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ (base_link <- head_camera_link)...")
    T_head_to_base = get_tf_transform('base_link', 'head_camera_link')
    
    if T_head_to_base is None:
        logging.error("âŒ æ— æ³•è·å–å¤´éƒ¨åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µï¼Œä½¿ç”¨é»˜è®¤å€¼")
        T_head_to_base = np.array([
            [-0.001, -0.749, 0.662, 0.365],
            [-1.000, 0.001, -0.001, 0.036],
            [-0.000, -0.662, -0.749, 1.516],
            [0.000, 0.000, 0.000, 1.000],
        ])
    else:
        logging.info("âœ“ æˆåŠŸè·å–å¤´éƒ¨åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ")
        print(f"T_head_to_base:\n{T_head_to_base}")
    
    # å®æ—¶è·å–æœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ (base_link <- left_arm_end_link)
    logging.info("è·å–æœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ (base_link <- left_arm_end_link)...")
    T_left_arm_to_base = get_tf_transform('base_link', 'left_arm_end_link')
    
    if T_left_arm_to_base is None:
        logging.warning("âš  æ— æ³•é€šè¿‡TFè·å–æœºæ¢°è‡‚æœ«ç«¯å˜æ¢ï¼Œä½¿ç”¨æœºå™¨äººAPI...")
        # å¦‚æœTFè·å–å¤±è´¥ï¼Œå°è¯•ä»æœºå™¨äººå½“å‰çŠ¶æ€è·å–
        try:
            left_arm_eef = mmk2.get_arm_ee_pose('left_arm')
            if left_arm_eef:
                position = left_arm_eef[0]  # [x, y, z]
                quaternion = left_arm_eef[1]  # [qx, qy, qz, qw]
                # æ³¨æ„ï¼šè¿™é‡Œè·å–çš„æ˜¯å½“å‰ä½å§¿ï¼Œä¸æ˜¯å˜æ¢çŸ©é˜µ
                # æˆ‘ä»¬éœ€è¦çš„æ˜¯æœºæ¢°è‡‚æœ«ç«¯åæ ‡ç³»åˆ°åŸºåº§çš„å˜æ¢
                # å¦‚æœæ— æ³•è·å–ï¼Œä½¿ç”¨é»˜è®¤å€¼
                logging.warning("ä½¿ç”¨é»˜è®¤çš„å·¦è‡‚æœ«ç«¯å˜æ¢çŸ©é˜µ")
                T_left_arm_to_base = np.array([
                    [0.042, 0.999, -0.012, 0.480],
                    [-0.999, 0.042, 0.004, 0.050],
                    [0.005, 0.012, 1.000, 1.330],
                    [0.000, 0.000, 0.000, 1.000],
                ])
            else:
                logging.error("æ— æ³•ä»æœºå™¨äººAPIè·å–å·¦è‡‚ä½å§¿ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                T_left_arm_to_base = np.array([
                    [0.042, 0.999, -0.012, 0.480],
                    [-0.999, 0.042, 0.004, 0.050],
                    [0.005, 0.012, 1.000, 1.330],
                    [0.000, 0.000, 0.000, 1.000],
                ])
        except Exception as e:
            logging.warning(f"è·å–å·¦è‡‚ä½å§¿æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            T_left_arm_to_base = np.array([
                [0.042, 0.999, -0.012, 0.480],
                [-0.999, 0.042, 0.004, 0.050],
                [0.005, 0.012, 1.000, 1.330],
                [0.000, 0.000, 0.000, 1.000],
            ])
    else:
        logging.info("âœ“ æˆåŠŸè·å–æœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ")
        print(f"T_left_arm_to_base:\n{T_left_arm_to_base}")
    
    # è·å–åˆå§‹ä½ç½®ï¼ˆä»æœºå™¨äººå½“å‰çŠ¶æ€ï¼‰
    try:
        left_arm_eef_init = mmk2.get_arm_ee_pose('left_arm')
        if left_arm_eef_init:
            init_pose = list(left_arm_eef_init[0]) + list(left_arm_eef_init[1])
            logging.info("âœ“ ä»æœºå™¨äººè·å–åˆå§‹ä½ç½®")
        else:
            init_pose = [0.4798196384291117, 0.050344892205700036, 1.3300944085789266,
                         0.004922124603778732, -0.003476176971870248, -0.6913608163682425, 0.7224845399547885]
            logging.info("ä½¿ç”¨é»˜è®¤åˆå§‹ä½ç½®")
    except Exception as e:
        logging.warning(f"è·å–åˆå§‹ä½ç½®æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        init_pose = [0.4798196384291117, 0.050344892205700036, 1.3300944085789266,
                     0.004922124603778732, -0.003476176971870248, -0.6913608163682425, 0.7224845399547885]
    
    # ============ 4. ä¸»å¾ªç¯ï¼šæ£€æµ‹å’ŒæŠ“å– ============
    print("\n" + "="*70)
    print("ğŸ” FDPè‡ªåŠ¨æ£€æµ‹æŠ“å–ç³»ç»Ÿï¼ˆä½¿ç”¨FDPå®Œæ•´ä½å§¿å¯¹é½æŠ“å–ï¼‰")
    print("="*70)
    print("æç¤º: æŒ‰ 'g' å¼€å§‹æŠ“å–, æŒ‰ 'r' é‡æ–°æ£€æµ‹, æŒ‰ 'q' é€€å‡º")
    print("="*70 + "\n")
    
    def detect_fdp():
        """æ‰§è¡ŒFDPæ£€æµ‹ï¼Œè¿”å›æ£€æµ‹åˆ°çš„å®Œæ•´ä½å§¿ï¼ˆä½ç½®+å§¿æ€ï¼‰"""
        logging.info("å¼€å§‹FDPæ£€æµ‹...")
        
        for img_head, img_depth, _, _ in camera:
            if img_head is None or img_depth is None:
                continue
            
            color = img_head.copy()
            depth = img_depth.astype(np.float32) / 1000.0
            
            logging.info("âœ“ è·å–åˆ°å›¾åƒ")
            
            # YOLOåˆ†å‰²
            results = yolo_model(color, verbose=False)
            
            if len(results) == 0 or results[0].masks is None:
                logging.warning("âŒ YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“")
                vis = color.copy()
                cv2.putText(vis, "YOLO Detection Failed - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])
                cv2.waitKey(1)
                return None, None, vis, None
            
            masks = results[0].masks.data.cpu().numpy()
            if len(masks) == 0:
                logging.warning("âŒ YOLOæœªæ£€æµ‹åˆ°ç‰©ä½“mask")
                vis = color.copy()
                cv2.putText(vis, "YOLO Mask Not Found - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])
                cv2.waitKey(1)
                return None, None, vis, None
            
            mask = masks[0]
            if mask.shape != color.shape[:2]:
                mask = cv2.resize(mask, (color.shape[1], color.shape[0]))
            mask = (mask > 0.5).astype(bool)
            yolo_mask = mask.copy()  # ä¿å­˜ç”¨äºå¯è§†åŒ–
            
            logging.info("âœ“ YOLOæ£€æµ‹æˆåŠŸ")
            
            # FDPä½å§¿ä¼°è®¡
            try:
                logging.info("æ­£åœ¨è¿›è¡ŒFDPä½å§¿ä¼°è®¡...")
                pose_result = est.register(K=K, rgb=color, depth=depth, ob_mask=mask, 
                                          iteration=args.est_refine_iter)
                
                if isinstance(pose_result, tuple):
                    pose_in_camera = pose_result[0]
                else:
                    pose_in_camera = pose_result
                
                # æå–ç‰©ä½“åœ¨ç›¸æœºåæ ‡ç³»çš„å®Œæ•´ä½å§¿
                point_fdp_camera_xyz = pose_in_camera[:3, 3].tolist()
                obj_rot_camera = pose_in_camera[:3, :3]
                obj_quat_camera = Rotation.from_matrix(obj_rot_camera).as_quat()
                
                # è·å–FDPç½®ä¿¡åº¦åˆ†æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                confidence_score = None
                if hasattr(est, 'scores') and est.scores is not None and len(est.scores) > 0:
                    confidence_score = float(est.scores[0])  # æœ€ä½³åŒ¹é…çš„åˆ†æ•°ï¼ˆå·²æ’åºï¼Œç¬¬ä¸€ä¸ªæœ€é«˜ï¼‰
                
                print("\n" + "="*70)
                print("ğŸ¯ FDPæ£€æµ‹æˆåŠŸï¼")
                print("="*70)
                print(f"ğŸ“ ç›¸æœºåæ ‡ç³»ä½ç½®: [{point_fdp_camera_xyz[0]:+.4f}, {point_fdp_camera_xyz[1]:+.4f}, {point_fdp_camera_xyz[2]:+.4f}] m")
                print(f"ğŸ¯ ç›¸æœºåæ ‡ç³»å››å…ƒæ•°: [{obj_quat_camera[0]:+.4f}, {obj_quat_camera[1]:+.4f}, {obj_quat_camera[2]:+.4f}, {obj_quat_camera[3]:+.4f}]")
                if confidence_score is not None:
                    print(f"ğŸ“Š FDPç½®ä¿¡åº¦åˆ†æ•°: {confidence_score:.4f}")
                print("="*70)
                
                logging.info("âœ“ FDPä½å§¿ä¼°è®¡å®Œæˆ")
                
                # å¯è§†åŒ–ï¼šæ˜¾ç¤ºYOLOåˆ†å‰²ã€ç»¿è‰²3Dæ¡†å’Œåæ ‡è½´
                vis = color.copy()
                
                # 1. ç»˜åˆ¶YOLOåˆ†å‰²mask
                if yolo_mask is not None:
                    # åŠé€æ˜æµ…è“è‰²é®ç½©
                    mask_overlay = vis.copy()
                    mask_overlay[yolo_mask] = (100, 200, 255)  # æµ…è“è‰² (BGRæ ¼å¼)
                    vis = cv2.addWeighted(mask_overlay, 0.3, vis, 0.7, 0)
                    
                    # é»„è‰²è½®å»“çº¿ï¼ˆç»†çº¿ï¼‰
                    mask_uint8 = (yolo_mask.astype(np.uint8) * 255)
                    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(vis, contours, -1, (0, 255, 255), 1)  # é»„è‰²ï¼Œçº¿å®½1
                    
                    # YOLO maskä¸­å¿ƒç‚¹
                    moments = cv2.moments(mask_uint8)
                    if moments['m00'] > 0:
                        mask_cx = int(moments['m10'] / moments['m00'])
                        mask_cy = int(moments['m01'] / moments['m00'])
                        cv2.circle(vis, (mask_cx, mask_cy), 4, (0, 0, 255), -1)  # çº¢è‰²åœ†ç‚¹
                        cv2.circle(vis, (mask_cx, mask_cy), 6, (255, 255, 255), 1)  # ç™½è‰²å¤–åœˆï¼ˆç»†ï¼‰
                        cv2.putText(vis, "YOLO", (mask_cx + 8, mask_cy - 8),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)  # å°å­—ä½“
                
                # 2. ç»˜åˆ¶FDPæ£€æµ‹ç»“æœ
                center_pose = pose_in_camera @ np.linalg.inv(to_origin)
                
                # ç»˜åˆ¶ç»¿è‰²3Dæ¡†ï¼ˆç»†çº¿ï¼‰
                vis = draw_posed_3d_box(K, img=vis, ob_in_cam=center_pose, bbox=bbox, linewidth=1)
                
                # ç»˜åˆ¶ä¸‰ä¸ªåæ ‡è½´ï¼ˆRGB: X=çº¢, Y=ç»¿, Z=è“ï¼Œç»†çº¿ï¼‰
                vis = draw_xyz_axis(vis, ob_in_cam=center_pose, scale=0.1, K=K, thickness=1, transparency=0, is_input_rgb=True)
                
                # FDPä¸­å¿ƒç‚¹
                obj_2d = K @ pose_in_camera[:3, 3]
                obj_2d = obj_2d / obj_2d[2]
                fdp_cx, fdp_cy = int(obj_2d[0]), int(obj_2d[1])
                if 0 <= fdp_cx < vis.shape[1] and 0 <= fdp_cy < vis.shape[0]:
                    cv2.drawMarker(vis, (fdp_cx, fdp_cy), (255, 0, 255), cv2.MARKER_CROSS, 12, 1)  # ç´«è‰²åå­—ï¼ˆç»†ï¼‰
                    cv2.putText(vis, "FDP", (fdp_cx + 8, fdp_cy + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 1)  # å°å­—ä½“
                
                # æ˜¾ç¤ºçŠ¶æ€æ–‡æœ¬å’Œç½®ä¿¡åº¦
                status_text = "Press 'g' to grasp, 'r' to retry, 'q' to quit"
                cv2.putText(vis, status_text, (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºç½®ä¿¡åº¦åˆ†æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if confidence_score is not None:
                    conf_text = f"FDP Score: {confidence_score:.3f}"
                    cv2.putText(vis, conf_text, (20, 55),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)  # é»„è‰²æ–‡å­—
                
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])  # RGB to BGR
                cv2.waitKey(1)
                
                return point_fdp_camera_xyz, obj_quat_camera, vis, confidence_score
                
            except Exception as e:
                logging.error(f"âŒ FDPä½å§¿ä¼°è®¡å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                
                # å³ä½¿FDPå¤±è´¥ï¼Œä¹Ÿæ˜¾ç¤ºYOLOåˆ†å‰²ç»“æœ
                vis = color.copy()
                if yolo_mask is not None:
                    # åŠé€æ˜æµ…è“è‰²é®ç½©
                    mask_overlay = vis.copy()
                    mask_overlay[yolo_mask] = (100, 200, 255)  # æµ…è“è‰² (BGRæ ¼å¼)
                    vis = cv2.addWeighted(mask_overlay, 0.3, vis, 0.7, 0)
                    
                    # é»„è‰²è½®å»“çº¿ï¼ˆç»†çº¿ï¼‰
                    mask_uint8 = (yolo_mask.astype(np.uint8) * 255)
                    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(vis, contours, -1, (0, 255, 255), 1)  # é»„è‰²ï¼Œçº¿å®½1
                    
                    # YOLO maskä¸­å¿ƒç‚¹
                    moments = cv2.moments(mask_uint8)
                    if moments['m00'] > 0:
                        mask_cx = int(moments['m10'] / moments['m00'])
                        mask_cy = int(moments['m01'] / moments['m00'])
                        cv2.circle(vis, (mask_cx, mask_cy), 4, (0, 0, 255), -1)  # çº¢è‰²åœ†ç‚¹
                        cv2.circle(vis, (mask_cx, mask_cy), 6, (255, 255, 255), 1)  # ç™½è‰²å¤–åœˆï¼ˆç»†ï¼‰
                        cv2.putText(vis, "YOLO", (mask_cx + 8, mask_cy - 8),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)  # å°å­—ä½“
                
                cv2.putText(vis, "FDP Detection Failed - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])  # RGB to BGR
                cv2.waitKey(1)
                
                return None, None, vis, None
            
            # åªå¤„ç†ç¬¬ä¸€å¸§
            break
        
        # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œè¿”å›ç©ºçš„å¯è§†åŒ–
        vis = None
        if img_head is not None:
            vis = img_head.copy()
            cv2.putText(vis, "No Image Captured - Press 'r' to retry, 'q' to quit", (20, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])
            cv2.waitKey(1)
        return None, None, vis, None
    
    def execute_grasp(point_fdp_camera_xyz, quat_fdp_camera, T_head_to_base_ref, T_left_arm_to_base_ref):
        """æ‰§è¡ŒæŠ“å–æµç¨‹ï¼ˆä½¿ç”¨FDPæ£€æµ‹çš„å®Œæ•´ä½å§¿è¿›è¡Œå¯¹é½å’ŒæŠ“å–ï¼‰"""
        print("\n" + "="*70)
        print("ğŸ¤– å¼€å§‹æ‰§è¡ŒæŠ“å–æµç¨‹ï¼ˆä½¿ç”¨FDPå®Œæ•´ä½å§¿å¯¹é½æŠ“å–ï¼‰...")
        print("="*70)
        
        # å®æ—¶æ›´æ–°å˜æ¢çŸ©é˜µï¼ˆå› ä¸ºå¤´éƒ¨è§’åº¦å¯èƒ½å·²æ”¹å˜ï¼‰
        logging.info("å®æ—¶æ›´æ–°å˜æ¢çŸ©é˜µ...")
        T_head_to_base = get_tf_transform('base_link', 'head_camera_link', timeout=3.0)
        if T_head_to_base is None:
            T_head_to_base = T_head_to_base_ref  # ä½¿ç”¨ä¼ å…¥çš„å˜æ¢çŸ©é˜µ
            logging.warning("æ— æ³•è·å–æœ€æ–°å˜æ¢çŸ©é˜µï¼Œä½¿ç”¨åˆå§‹å€¼")
        else:
            logging.info("âœ“ å·²æ›´æ–°å¤´éƒ¨åˆ°åŸºåº§çš„å˜æ¢çŸ©é˜µ")
        
        # ä½¿ç”¨ä¼ å…¥çš„å·¦è‡‚å˜æ¢çŸ©é˜µï¼ˆé€šå¸¸ä¸ä¼šæ”¹å˜ï¼‰
        T_left_arm_to_base = T_left_arm_to_base_ref
        
        # åæ ‡å˜æ¢ï¼šç›¸æœº â†’ åŸºåº§ï¼ˆä½ç½®ï¼‰
        point_fdp_base_xyz = transform_point(point_fdp_camera_xyz, T_head_to_base)
        
        # å§¿æ€å˜æ¢ï¼šç›¸æœº â†’ åŸºåº§ï¼ˆå§¿æ€ï¼‰
        quat_fdp_base = transform_quaternion(quat_fdp_camera, T_head_to_base)
        
        logging.info(f"FDPæ£€æµ‹ä½ç½®ï¼ˆåŸºåº§ï¼‰: [{point_fdp_base_xyz[0]:+.4f}, {point_fdp_base_xyz[1]:+.4f}, {point_fdp_base_xyz[2]:+.4f}] m")
        logging.info(f"FDPæ£€æµ‹å§¿æ€ï¼ˆåŸºåº§ï¼‰: [{quat_fdp_base[0]:+.4f}, {quat_fdp_base[1]:+.4f}, {quat_fdp_base[2]:+.4f}, {quat_fdp_base[3]:+.4f}]")
        
        # è®¡ç®—å‡†å¤‡ä½ç½®ï¼ˆç‰©ä½“ä¸Šæ–¹15cmï¼Œä½¿ç”¨FDPå®Œæ•´å§¿æ€ï¼‰
        # åœ¨åŸºåº§åæ ‡ç³»ä¸‹ï¼Œæ²¿FDPæ£€æµ‹çš„Zè½´æ–¹å‘å‘ä¸Šç§»åŠ¨15cm
        R_fdp_base = Rotation.from_quat(quat_fdp_base).as_matrix()
        z_axis_fdp = R_fdp_base[:, 2]  # FDPæ£€æµ‹çš„Zè½´æ–¹å‘ï¼ˆç‰©ä½“åæ ‡ç³»ï¼‰
        approach_offset = 0.15  # 15cm
        point_prepare_base_xyz = point_fdp_base_xyz + z_axis_fdp * approach_offset
        
        print(f"\nå‡†å¤‡ä½ç½®ï¼ˆåŸºåº§ï¼Œç‰©ä½“ä¸Šæ–¹15cmï¼‰: [{point_prepare_base_xyz[0]:+.4f}, {point_prepare_base_xyz[1]:+.4f}, {point_prepare_base_xyz[2]:+.4f}] m")
        
        # æ­¥éª¤1ï¼šä½å§¿å¯¹é½ - ç§»åŠ¨åˆ°å‡†å¤‡ä½ç½®ï¼ˆä½¿ç”¨FDPå®Œæ•´ä½å§¿ï¼‰
        logging.info("[1/6] ä½å§¿å¯¹é½ - ç§»åŠ¨åˆ°å‡†å¤‡ä½ç½®ï¼ˆç‰©ä½“ä¸Šæ–¹15cmï¼Œä½¿ç”¨FDPå®Œæ•´ä½å§¿ï¼‰...")
        mmk2.set_robot_eef('left_arm', 1)  # æ‰“å¼€å¤¹çˆª
        point_prepare_base = list(point_prepare_base_xyz) + list(quat_fdp_base)  # ä½¿ç”¨FDPå®Œæ•´ä½å§¿
        mmk2.control_arm_pose('left_arm', point_prepare_base)
        time.sleep(2.5)  # æš‚åœï¼Œè§‚å¯Ÿå¯¹é½æ•ˆæœ
        
        # æ­¥éª¤2ï¼šæ‰“å¼€å¤¹çˆª
        logging.info("[2/6] æ‰“å¼€å¤¹çˆª...")
        mmk2.set_robot_eef('left_arm', 1)  # ç¡®ä¿æ‰“å¼€
        time.sleep(1.0)
        
        # æ­¥éª¤3ï¼šä¸‹é™åˆ°æŠ“å–ä½ç½®ï¼ˆç‰©ä½“ä¸Šæ–¹3cmï¼Œä½¿ç”¨FDPå®Œæ•´ä½å§¿ï¼‰
        logging.info("[3/6] ä¸‹é™åˆ°æŠ“å–ä½ç½®ï¼ˆç‰©ä½“ä¸Šæ–¹3cmï¼‰...")
        grasp_offset = 0.03  # 3cm
        point_grasp_base_xyz = point_fdp_base_xyz + z_axis_fdp * grasp_offset
        print(f"æŠ“å–ä½ç½®ï¼ˆåŸºåº§ï¼‰: [{point_grasp_base_xyz[0]:+.4f}, {point_grasp_base_xyz[1]:+.4f}, {point_grasp_base_xyz[2]:+.4f}] m")
        
        point_grasp_base = list(point_grasp_base_xyz) + list(quat_fdp_base)  # ä½¿ç”¨FDPå®Œæ•´ä½å§¿
        mmk2.control_arm_pose('left_arm', point_grasp_base)
        time.sleep(2.0)
        
        # æ­¥éª¤4ï¼šé—­åˆå¤¹çˆªæŠ“å–
        logging.info("[4/6] é—­åˆå¤¹çˆªæŠ“å–...")
        mmk2.set_robot_eef('left_arm', 0)  # å…³é—­å¤¹çˆª
        time.sleep(1.5)
        
        # æ­¥éª¤5ï¼šæŠ¬èµ·ï¼ˆç‰©ä½“ä¸Šæ–¹5cmï¼Œä½¿ç”¨FDPå®Œæ•´ä½å§¿ï¼‰
        logging.info("[5/6] æŠ¬èµ·ç‰©ä½“ï¼ˆç‰©ä½“ä¸Šæ–¹5cmï¼‰...")
        lift_offset = 0.05  # 5cm
        point_lift_base_xyz = point_fdp_base_xyz + z_axis_fdp * lift_offset
        point_lift_base = list(point_lift_base_xyz) + list(quat_fdp_base)  # ä½¿ç”¨FDPå®Œæ•´ä½å§¿
        mmk2.control_arm_pose('left_arm', point_lift_base)
        time.sleep(2.0)
        
        # æ­¥éª¤6ï¼šè¿”å›åˆ°åˆå§‹ä½ç½®
        logging.info("[6/6] è¿”å›åˆ°åˆå§‹ä½ç½®...")
        mmk2.control_arm_pose('left_arm', init_pose)
        time.sleep(2.0)
        mmk2.set_robot_eef('left_arm', 1)  # æ‰“å¼€å¤¹çˆªï¼ˆé‡Šæ”¾ç‰©ä½“ï¼‰
        mmk2.set_robot_eef('left_arm', 0)  # å…³é—­å¤¹çˆª
        
        print("\n" + "="*70)
        print("âœ… æŠ“å–æµç¨‹å®Œæˆï¼")
        print("="*70)
        print("æç¤º: æŒ‰ 'r' é‡æ–°æ£€æµ‹, æŒ‰ 'q' é€€å‡º")
    
    # ä¸»å¾ªç¯
    point_fdp_camera_xyz = None
    quat_fdp_camera = None
    vis = None
    confidence_score = None
    
    while True:
        # æ‰§è¡ŒFDPæ£€æµ‹
        point_fdp_camera_xyz, quat_fdp_camera, vis, confidence_score = detect_fdp()
        
        if point_fdp_camera_xyz is None or quat_fdp_camera is None:
            logging.warning("âŒ æ£€æµ‹å¤±è´¥ï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ...")
            # æ˜¾ç¤ºé”™è¯¯æç¤º
            if vis is not None:
                cv2.putText(vis, "Detection Failed - Press 'r' to retry, 'q' to quit", (20, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.imshow('FDP Auto Grasp - Detection', vis[...,::-1])
            
            # ç­‰å¾…ç”¨æˆ·æŒ‰é”®
            while True:
                key = cv2.waitKey(100) & 0xFF
                if key == ord('q'):
                    logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                    cv2.destroyAllWindows()
                    return
                elif key == ord('r'):
                    logging.info("é‡æ–°æ£€æµ‹...")
                    break
            continue
        
        # ç­‰å¾…ç”¨æˆ·æŒ‰é”®ï¼ˆæ£€æµ‹æˆåŠŸï¼‰
        while True:
            key = cv2.waitKey(100) & 0xFF
            if key == ord('q'):
                logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                cv2.destroyAllWindows()
                return
            elif key == ord('g'):
                execute_grasp(point_fdp_camera_xyz, quat_fdp_camera, T_head_to_base, T_left_arm_to_base)
                # æŠ“å–å®Œæˆåï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ
                while True:
                    key = cv2.waitKey(100) & 0xFF
                    if key == ord('q'):
                        logging.info("ç”¨æˆ·é€€å‡ºç¨‹åº")
                        cv2.destroyAllWindows()
                        return
                    elif key == ord('r'):
                        logging.info("é‡æ–°æ£€æµ‹...")
                        break
                break
            elif key == ord('r'):
                logging.info("é‡æ–°æ£€æµ‹...")
                break

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ä¸­æ–­")
        cv2.destroyAllWindows()
    except Exception as e:
        logging.error(f"ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        cv2.destroyAllWindows()

